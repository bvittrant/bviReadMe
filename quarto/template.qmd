---
title: "Template"
author: "Benjamin Vittrant"
format: 
  html: 
   toc: true
   code-fold: true
   number-sections: true
   number-depth: 2
   anchor-sections: true
   smooth-scroll: true
editor: visual
license: "Copyright Benjamin Vittrant, 2022. All Rights Reserved. The diffusion, reuse or distribution of this document is not allowed."
bibliography: references.bib
---

# Disclaimer

::: callout-important
-   This work is only made for internal diffusion
-   Ask permission for any image/text/information re-sharing
:::

# Introduction

## Context

## Objectives

## Be aware

::: callout-note
:::

::: callout-warning
:::

::: callout-important
:::

::: callout-tip
:::

::: caution
:::

# Code set-up

## Clean

This small piece of code makes sure the env and all object are cleared before starting the work.

```{r, message=F, warning=F}
rm(list = ls(all.names = TRUE))
```

## Functions

In this part you can find some useful basic functions to process and analyse data.

```{r, message=F, warning=F}
# Install load pkg
install_and_load_packages <- function(pkg_names) {
  for (pkg_name in pkg_names) {
    if (!requireNamespace(pkg_name, quietly = TRUE)) {
      tryCatch({
        if (substr(pkg_name, 1, 2) == "Bi") {
          # Bioconductor package
          BiocManager::install(pkg_name)
          library(pkg_name, character.only = TRUE)
        } else {
          # CRAN package
          install.packages(pkg_name)
          library(pkg_name, character.only = TRUE)
        }
      }, error = function(e) {
        message("Failed to install and load package: ", pkg_name)
      })
    } else {
      library(pkg_name, character.only = TRUE)
    }
  }
}

# Remove duplicated rows
remove_duplicated_rows <- function(df, cols_to_check) {
  # identify the duplicated rows based on the specified columns
  dup_rows <- duplicated(df[, cols_to_check]) | duplicated(df[, cols_to_check], fromLast = TRUE)
  
  # remove the duplicated rows
  df_unique <- df[!dup_rows, ]
  
  # return the updated dataframe
  return(df_unique)
}

# Convert col to character type
convert_cols_to_character <- function(df, colnames_to_convert) {
  # loop through each column name and convert to character type
  for (colname in colnames_to_convert) {
    df[[colname]] <- as.character(df[[colname]])
  }
  
  # return the updated dataframe
  return(df)
}

summary_quant = function(data){return(get_summary_stats(data, type="quantile", probs = c(0.1,0.25, 0.5,0.75,0.9)))}
```

## Packages

In this part I will install and load the needed packages for the work.

```{r, message=F, warning=F}

list_pkg = c("BiocManager","ggsci", "plotly", "GGally", "reshape2","webshot2" ,"gtsummary", "tidyr", "polycor", "rstatix",
             "ComplexHeatmap", "circlize", "cowplot", "dplyr", "reticulate", "renv", "report", "easystats")
install_and_load_packages(list_pkg)

```

## Env

Initialize a specific R env to work in a isolated env properly. Packages are saved within the renv.lock file.

```{r, message=F, warning=F, eval=F}
renv::init()
```

## Colors

We define color palette from the *ggsci* [@xiao__aut_ggsci_2023] that recreate color from scientific publication.

```{r, message=F}
discrete_ggsci_npg = list(scale_color_npg(), scale_fill_npg())
continuous_ggsci_npg = list(scale_fill_material("light-blue"))
palette = "Paired"
```

## Paths

Set some paths.

```{r, message=F}
path_to_figure = "Figures/"
```


# Data collection and preprocessing

In this part I will download, process and store the data that will be used during our work. I also manage here if it is needed to re-run all the processing steps.

```{r, message=F, warning=F}

# Check if R object exists
if(file.exists("../data/raw/internal/main.RData")){
  
  # Load data in R object if it exists
  base::load("../data/raw/internal/main.RData")
  
} else {
  
  # YOUR STUFF leading to any data
  #path = "../../dir/"
  #file_names <- dir(path) #where you have your files
  #data <- do.call(rbind, lapply(paste(path, file_names, sep=""), function(file) read.table(file, header=TRUE, sep=";")))

  # Save the data
  #resave(data file = "../data/raw/internal/main.RData")
  save(data, file = "../data/raw/internal/main.RData")
}
```

# Data descritpion

In this part I will produce description table usable for publication. I used the gt table

```{r, message=F, warning=F}
#table_measures = gtsummary::tbl_summary(
#  tmp, 
#  #type = all_continuous() ~ "continuous2",
#  statistic = list(all_continuous() ~ c("{mean} ({sd})"),  all_categorical() ~ "{n} ({p}%)"),
#  #label  = list_labels,
#  #missing = "no",
#  missing_text = "Missing",
#  by=Sex,
#  digits = all_continuous() ~ 1
#) %>% italicize_levels() %>% bold_labels() %>% add_overall() #%>% add_difference() # Possible if b has 2 levels

#as_gt(table_measures)
#as_gt(table_measures) %>% gt::gtsave(filename = paste(path_to_figure, "table_data_summary_measures.pdf", sep=""))
#table_measures %>% gtsummary::as_tibble() %>%
#writexl::write_xlsx(., paste(path_to_figure, "table_data_summary_measures.xlxs", sep=""))
```

# Exploration

## Distribution

```{r, message=F, warning=F}

```

The distribution can also be checked using a correlogram where feature distribution is the diagonal part. This graph is created from the *GGally* [@schloerke_ggally_2021] library which extend the ggplot 2 capabilities. You need to reduce matrix input or can take a lot of time nad the plot can be unreadable if you have to much features.

```{r, message=F, warning=F}

```

## Summary statistics

For the summary statistics I used the package from *rstatix* [@kassambara_rstatix_2023] function.

```{r, message=F, warning=F}

```

## Correlation

For the correlation analysis I used the pacakge *polycor* [@fox_polycor_2022, @noauthor_polychoric_2023] which is based on polychoric and polyserial correlation [@drasgow_polychoric_2006].

```{r, message=F, warning=F}

```
## Plot

### Ribbons

```{r}
#p_age = ggplot(data_summary_age) +
#  geom_line(aes(age, `50%`, colour = "50%")) + xlab("") + ylab("") +
#  ggtitle("(A)") + theme(legend.position = "None") +
#  geom_ribbon(aes(ymin=`25%`, ymax=`75%`, x=age, fill = "25% < median < 75%"), alpha = 0.3)+
#  geom_ribbon(aes(ymin=`10%`, ymax=`90%`, x=age, fill = "10% < median < 90%"), alpha = 0.1)+
#  scale_color_npg(name = "") +
#  scale_fill_npg(name="") +
#  geom_hline(yintercept=thresh_down, linetype="dashed", color = "darkred", linewidth=0.5) +
#  geom_hline(yintercept=thresh_up, linetype="dashed", color = "darkgreen", linewidth=0.5)
#p_age
```

### Plot with statistics

```{r}
# Create data and specify the test we need
#tab_res = compare_means(value ~ minute_floor_cat, method = "t.test",  data = na.omit(d))
#my_comparisons <- list( c("0h-10h", "10h-19h"), c("10h-19h", "19h-24h"))
                   
#p_boxplot_minute_cat = ggplot(na.omit(d), aes(minute_floor_cat, value)) +
#  geom_boxplot() + ylab("ESC") + xlab("") + labs(color='Time') +
#  scale_color_npg() + 
#  scale_y_continuous(name="", limits=c(0, 110), breaks=c(0, 25, 50, 75, 100)) +
#  ylab("") + xlab("") + ggtitle("(A)") +
#  stat_compare_means(comparisons = my_comparisons, method = "t.test", label.y = 101, label = "p.signif")
#p_boxplot_minute_cat
```

## Mutual information

```{r, message=F, warning=F}
```

## Heatmap

To plot the heat map I used the unbelieveable package *complex heatmap* [@gu_complex_2016, @gu_complex_2022]. All the doc is availabel on the [github page](https://jokergoo.github.io/ComplexHeatmap-reference/book/index.html).

```{r, message=F, warning=F}
# Select data
#n = 1000
#data_heatmap = data
#data_heatmap_num = data_num
#mat_heatmap = scale(log(data_heatmap_num[1:n,]+1)) %>% as.matrix()

#mat_heatmap = data_num[1:n,] %>% as.matrix()

# Define annotation
#column_ha = HeatmapAnnotation(Barplot = anno_density(mat_heatmap, type = "violin"))
#row_ha = rowAnnotation(Age = data_heatmap[1:n, "age"], Gender = data_heatmap[1:n, "gender"], Continent = data_heatmap[1:n, "continent"], Height = data_heatmap[1:n, "height"])

# Definine color function
#col_fun = colorRamp2(c(-2, 0, 2), hcl_palette = "Tropic")

# Define split
#r_split = data_heatmap.frame(data[1:n, "year"], data[1:n, "continent"])
#r_split = data_heatmap[1:n, "gender"]

# Create the heatmap
#ht = Heatmap(mat_heatmap , show_row_names = F, right_annotation = row_ha, top_annotation = column_ha, col = col_fun,
#        row_split = r_split)
#ht
# save the heamap
#pdf("plot_exploration_diabetic_foot_heatmap.pdf", width = 20, height = 15)
#draw(ht)
#dev.off()

```

# Model selection and training

```{r, message=F, warning=F}
```

# Model evaluation

```{r, message=F, warning=F}
```

# Conclusion

```{r, message=F, warning=F}
```

# Discussion

```{r, message=F, warning=F}
```

# Futur work

```{r, message=F, warning=F}
```

# Thanks

I'd like to thank the scikit-Learn team in general for their amazing work [@pedregosa_scikit-learn_2011; @buitinck_api_2013] and also the *Stack Overflow* [@noauthor_stack_nodate] community and *Github* [@noauthor_github_nodate] for providing code repository.

# References

::: {#refs}
:::
